{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_BI_GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQ4QqeXuUD9URpNXV9fy7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepOde/tones2tunes/blob/main/models/Model_BI_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrrF7t5cpoJ0"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMSYmUwH2c0A"
      },
      "source": [
        "class Tones2Tunes(nn.Module):\n",
        "  def __init__(self,unique_notes,dropout=0.3,output_emb=100,rnn_unit=128, dense_unit=64):\n",
        "    super().__init__()\n",
        "    # this indicates the vocabulary(unique notes in the whole input)\n",
        "    self.num_embeddings=unique_notes+1\n",
        "    # this indicates the vector representation size for each note\n",
        "    self.embedding_dim=output_emb\n",
        "    # No of hidden layers in GRU\n",
        "    self.hidden_unit=rnn_unit\n",
        "    # creating embedding layer\n",
        "    self.embedding=nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
        "    # creating bidirectional GRU\n",
        "    # by default pytorch returns all the hidden state repre's\n",
        "    # for more read this [@ https://discuss.pytorch.org/t/pytorch-equivalent-to-keras-layers-lstm-return-sequences-false/53976/2]\n",
        "    self.BiGRU1=nn.GRU(self.embedding_dim,self.hidden_unit,bidirectional=True,batch_first=True)\n",
        "    # have to implement self attention(Have to check)\n",
        "\n",
        "    # adding dropout\n",
        "    self.dropout1 = nn.Dropout(dropout)\n",
        "    # adding BIGRU\n",
        "    self.BiGRU2=nn.GRU(self.hidden_unit,self.hidden_unit,bidirectional=True,batch_first=True)\n",
        "    # adding dropout\n",
        "    self.dropout2 = nn.Dropout(dropout)\n",
        "    # adding fully connected layer\n",
        "    self.fc = nn.Linear(self.hidden_unit, unique_notes+1)\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "  def forward(self,x):\n",
        "    x=self.embedding(x)\n",
        "    # print(x.shape)\n",
        "    output, ht=self.BiGRU1(x)\n",
        "    # print(output.shape,ht.shape)\n",
        "    output=output[:,:,:128]+output[:,:,128:]\n",
        "    output=self.dropout1(output)\n",
        "    output,ht =self.BiGRU2(output)\n",
        "    # print(output.shape,ht.shape)\n",
        "    output=ht[-1]\n",
        "    output=self.dropout2(output)\n",
        "    output=self.fc(output)\n",
        "    output=self.softmax(output)\n",
        "    return output   \n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzWZp-XiX-OE"
      },
      "source": [
        "def accuracy(yhat,Y_train):\n",
        "  pred=torch.argmax(yhat,dim=1)\n",
        "  return (pred==Y_train).float().mean()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg4HBjCC5uYh"
      },
      "source": [
        "losses=[]\n",
        "acc=[]\n",
        "def fit(model,opt,X_train,Y_train,epochs=1000):\n",
        "  for i in range(epochs):\n",
        "    # have to send batches here\n",
        "    yhat=model(X_train)\n",
        "    loss=F.cross_entropy(yhat,Y_train)\n",
        "    loss.backward()\n",
        "    losses.append(loss)\n",
        "    ac=accuracy(yhat,Y_train)\n",
        "    acc.append(ac)\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    if(i%100==0):\n",
        "      print(\"Iteration : \",i)\n",
        "      print(\"Loss : \"+str(loss.item()))\n",
        "      print(\"Accuarcy : \"+str(ac.item()))\n",
        "  plt.plot(losses,'r')\n",
        "  plt.plot(acc,'b')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0qz1oMVZcVl"
      },
      "source": [
        "def predict(X_test):\n",
        "  return torch.argmax(model(X_test),dim=-1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ3woZPFgWHE"
      },
      "source": [
        "# Testing the model with dummy data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV76eqgZZ6dc"
      },
      "source": [
        "X_train=torch.randint(0,100,(100,100))\n",
        "Y_train=torch.randint(0,100,(100,1))\n",
        "Y_train=Y_train.reshape(-1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX3e9_kQaQVM",
        "outputId": "e7aed397-f0b2-4c54-b4c0-faeaa29e12dd"
      },
      "source": [
        "X_train,Y_train= map(torch.tensor,(X_train,Y_train))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2z2C4dzapcf",
        "outputId": "2e4c2163-aae5-4b60-cef4-e800826608c7"
      },
      "source": [
        "# Hyperparameters\n",
        "lr=0.01\n",
        "epochs=1000\n",
        "\n",
        "# creating CUDA device\n",
        "if(torch.cuda.device_count()>0):\n",
        "  dev=\"cuda\"\n",
        "  print(\"CUDA available\")\n",
        "else:\n",
        "  dev=\"cpu\"\n",
        "  print(\"No CUDA\")\n",
        "device=torch.device(dev)\n",
        "X_train=X_train.to(device)\n",
        "Y_train=Y_train.to(device)\n",
        "\n",
        "# Creating an object of the model\n",
        "model=Tones2Tunes(100)\n",
        "\n",
        "# Moving the model to GPU\n",
        "model.to(device)\n",
        "\n",
        "# Creating the optimizer\n",
        "opt=optim.SGD(model.parameters(),lr=lr)\n",
        "\n",
        "# Training the model\n",
        "fit(model,opt,X_train,Y_train,epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No CUDA\n",
            "Iteration :  0\n",
            "Loss : 4.6149983406066895\n",
            "Accuarcy : 0.009999999776482582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkB87aylbwb7"
      },
      "source": [
        "# Prediction \n",
        "y_pred=predict(X_train)\n",
        "accuracy(model(X_train),Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4bXXAJceoN3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}